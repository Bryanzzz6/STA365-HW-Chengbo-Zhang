{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1bb737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set parameters\n",
    "n = 30  # Sample size\n",
    "m = 0   # True mean\n",
    "s = 1   # True standard deviation\n",
    "x = stats.norm(loc=m, scale=s).rvs(size=n)  # Simulated data\n",
    "\n",
    "# Prior hyperparameters\n",
    "theta0 = 0    # Prior mean for theta\n",
    "tau0_sq = 1   # Prior variance for theta\n",
    "alpha = 2     # Shape parameter for tau\n",
    "lambda_ = 1   # Rate parameter for tau\n",
    "\n",
    "# Metropolis within Gibbs parameters\n",
    "C, G = 2, 10000  # Chains, Gibbs samples\n",
    "theta, tau = np.zeros((C, G)), np.zeros((C, G))\n",
    "theta[:, 0] = 1000  # Initialize theta\n",
    "tau[:, 0] = 1       # Initialize tau\n",
    "\n",
    "# Independent proposal distribution for tau\n",
    "proposal_shape, proposal_rate = alpha, lambda_  # Gamma proposal\n",
    "\n",
    "# Joint density function (up to proportionality)\n",
    "def log_joint_density(theta, tau):\n",
    "    log_prior_theta = -0.5 * (theta - theta0) ** 2 / tau0_sq  # Normal prior\n",
    "    log_prior_tau = (alpha - 1) * np.log(tau) - lambda_ * tau  # Gamma prior\n",
    "    log_likelihood = -0.5 * tau * np.sum((x - theta) ** 2)  # Gaussian likelihood\n",
    "    return log_prior_theta + log_prior_tau + log_likelihood\n",
    "\n",
    "# Metropolis within Gibbs sampling\n",
    "for c in range(C):\n",
    "    for g in range(1, G):\n",
    "        # Gibbs update for theta\n",
    "        mean_theta = (tau[c, g-1] * np.sum(x) + theta0 / tau0_sq) / (tau[c, g-1] * n + 1 / tau0_sq)\n",
    "        var_theta = 1 / (tau[c, g-1] * n + 1 / tau0_sq)\n",
    "        theta[c, g] = stats.norm.rvs(loc=mean_theta, scale=np.sqrt(var_theta))\n",
    "        \n",
    "        # Metropolis-Hastings update for tau\n",
    "        tau_proposed = stats.gamma.rvs(a=proposal_shape, scale=1/proposal_rate)\n",
    "        log_acceptance_ratio = log_joint_density(theta[c, g], tau_proposed) - log_joint_density(theta[c, g], tau[c, g-1])\n",
    "        \n",
    "        if np.log(stats.uniform.rvs()) < log_acceptance_ratio:\n",
    "            tau[c, g] = tau_proposed  # Accept proposal\n",
    "        else:\n",
    "            tau[c, g] = tau[c, g-1]  # Reject proposal and keep previous tau\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "for c in range(C):\n",
    "    axes[0, 0].plot(theta[c, :], alpha=0.5, label=f'Chain {c+1}')\n",
    "    axes[1, 0].plot(tau[c, :], alpha=0.5, label=f'Chain {c+1}')\n",
    "    axes[0, 1].hist(theta[c, :], bins=30, density=True, alpha=0.5, label=f'Chain {c+1}')\n",
    "    axes[1, 1].hist(tau[c, :], bins=30, density=True, alpha=0.5, label=f'Chain {c+1}')\n",
    "\n",
    "axes[0, 0].set_title(\"Theta Trace Plot\")\n",
    "axes[1, 0].set_title(\"Tau Trace Plot\")\n",
    "axes[0, 1].set_title(\"Theta Posterior Distribution\")\n",
    "axes[1, 1].set_title(\"Tau Posterior Distribution\")\n",
    "for ax in axes.flatten(): ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show(\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae539c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set parameters\n",
    "n = 30  # Sample size\n",
    "m = 0   # True mean\n",
    "s = 1   # True standard deviation\n",
    "x = stats.norm(loc=m, scale=s).rvs(size=n)  # Simulated data\n",
    "\n",
    "# Prior hyperparameters\n",
    "theta0 = 0    # Prior mean for theta\n",
    "tau0_sq = 1   # Prior variance for theta\n",
    "alpha = 2     # Shape parameter for tau\n",
    "lambda_ = 1   # Rate parameter for tau\n",
    "\n",
    "# Metropolis within Gibbs parameters\n",
    "C, G = 2, 10000  # Chains, Gibbs samples\n",
    "theta, tau = np.zeros((C, G)), np.zeros((C, G))\n",
    "theta[:, 0] = 1000  # Initialize theta\n",
    "tau[:, 0] = 1       # Initialize tau\n",
    "\n",
    "# Non-Normal prior for theta (e.g., Uniform prior)\n",
    "def log_prior_theta(theta):\n",
    "    return np.where((-10 <= theta) & (theta <= 10), 0, -np.inf)  # Uniform prior on [-10,10]\n",
    "\n",
    "# Joint density function (up to proportionality)\n",
    "def log_joint_density(theta, tau):\n",
    "    log_prior_tau = (alpha - 1) * np.log(tau) - lambda_ * tau  # Gamma prior\n",
    "    log_likelihood = -0.5 * tau * np.sum((x - theta) ** 2)  # Gaussian likelihood\n",
    "    return log_prior_theta(theta) + log_prior_tau + log_likelihood\n",
    "\n",
    "# Metropolis within Gibbs sampling\n",
    "for c in range(C):\n",
    "    for g in range(1, G):\n",
    "        # Metropolis-Hastings update for theta with non-normal prior\n",
    "        theta_proposed = stats.uniform.rvs(-10, 20)  # Sample from Uniform prior\n",
    "        log_acceptance_ratio = log_joint_density(theta_proposed, tau[c, g-1]) - log_joint_density(theta[c, g-1], tau[c, g-1])\n",
    "        \n",
    "        if np.log(stats.uniform.rvs()) < log_acceptance_ratio:\n",
    "            theta[c, g] = theta_proposed  # Accept proposal\n",
    "        else:\n",
    "            theta[c, g] = theta[c, g-1]  # Reject proposal\n",
    "        \n",
    "        # Metropolis-Hastings update for tau with dependent proposal\n",
    "        tau_t_minus_1 = tau[c, g-1]\n",
    "        proposal_dist = stats.truncnorm(a=-tau_t_minus_1/s, b=np.inf, loc=tau_t_minus_1, scale=s)\n",
    "        tau_proposed = proposal_dist.rvs()\n",
    "        log_acceptance_ratio = log_joint_density(theta[c, g], tau_proposed) - log_joint_density(theta[c, g], tau[c, g-1])\n",
    "        \n",
    "        if np.log(stats.uniform.rvs()) < log_acceptance_ratio:\n",
    "            tau[c, g] = tau_proposed  # Accept proposal\n",
    "        else:\n",
    "            tau[c, g] = tau[c, g-1]  # Reject proposal\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "for c in range(C):\n",
    "    axes[0, 0].plot(theta[c, :], alpha=0.5, label=f'Chain {c+1}')\n",
    "    axes[1, 0].plot(tau[c, :], alpha=0.5, label=f'Chain {c+1}')\n",
    "    axes[0, 1].hist(theta[c, :], bins=30, density=True, alpha=0.5, label=f'Chain {c+1}')\n",
    "    axes[1, 1].hist(tau[c, :], bins=30, density=True, alpha=0.5, label=f'Chain {c+1}')\n",
    "\n",
    "axes[0, 0].set_title(\"Theta Trace Plot\")\n",
    "axes[1, 0].set_title(\"Tau Trace Plot\")\n",
    "axes[0, 1].set_title(\"Theta Posterior Distribution\")\n",
    "axes[1, 1].set_title(\"Tau Posterior Distribution\")\n",
    "for ax in axes.flatten(): ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show(\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cad348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2, continued \n",
    "#In Gibbs sampling, deriving the full conditional distributions is essential but can be analytically challenging \n",
    "#or infeasible for complex models. When available, these full conditionals make Gibbs sampling computationally \n",
    "#efficient with high acceptance rates. However, when they are intractable, the Metropolis-Hastings within Gibbs \n",
    "#approach provides a practical alternative by enabling sampling from the joint posterior using proposal \n",
    "#distributions. This method offers greater flexibility, allowing the use of tailored proposal distributions to \n",
    "#improve efficiency and priors that complicate direct conditional derivation, making it a versatile tool for \n",
    "#Bayesian inference in complex scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b2a330",
   "metadata": {},
   "source": [
    "#Q3\n",
    "\n",
    "\n",
    "The proposal distribution is defined as:\n",
    "$$\n",
    "q\\left(\\tilde{x}^{(t)} \\mid x^{(t-1)}\\right) = \\left(\\frac{1}{2}\\right)^{1-\\tilde{x}^{(t)}} \\left(\\frac{1}{2}\\right)^{\\tilde{x}^{(t)}},\n",
    "$$\n",
    "which is symmetric, meaning:\n",
    "$$\n",
    "q(0 \\mid 1) = q(1 \\mid 0) = \\frac{1}{2}, \\quad q(0 \\mid 0) = q(1 \\mid 1) = \\frac{1}{2}.\n",
    "$$\n",
    "\n",
    "\n",
    "The stationary distribution is given as:\n",
    "$$\n",
    "p\\left(x^{(t)}\\right) = \\left(\\frac{1}{3}\\right)^{1-x^{(t)}} \\left(\\frac{2}{3}\\right)^{x^{(t)}},\n",
    "$$\n",
    "implying:\n",
    "$$\n",
    "p(0) = \\frac{1}{3}, \\quad p(1) = \\frac{2}{3}.\n",
    "$$\n",
    "\n",
    "The acceptance probability in the Metropolis-Hastings algorithm is:\n",
    "$$\n",
    "\\alpha\\left(x^{(t-1)} \\rightarrow \\tilde{x}^{(t)}\\right) = \\min \\left(1, \\frac{p\\left(\\tilde{x}^{(t)}\\right)}{p\\left(x^{(t-1)}\\right)} \\frac{q\\left(x^{(t-1)} \\mid \\tilde{x}^{(t)}\\right)}{q\\left(\\tilde{x}^{(t)} \\mid x^{(t-1)}\\right)}\\right).\n",
    "$$\n",
    "\n",
    "Since the proposal distribution is symmetric, the ratio of proposals cancels out:\n",
    "$$\n",
    "\\frac{q\\left(x^{(t-1)} \\mid \\tilde{x}^{(t)}\\right)}{q\\left(\\tilde{x}^{(t)} \\mid x^{(t-1)}\\right)} = 1.\n",
    "$$\n",
    "\n",
    "Thus, the acceptance probability simplifies to:\n",
    "$$\n",
    "\\alpha\\left(x^{(t-1)} \\rightarrow \\tilde{x}^{(t)}\\right) = \\min \\left(1, \\frac{p\\left(\\tilde{x}^{(t)}\\right)}{p\\left(x^{(t-1)}\\right)}\\right).\n",
    "$$\n",
    "\n",
    "Substituting \\( p(0) = \\frac{1}{3} \\) and \\( p(1) = \\frac{2}{3} \\), we compute:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\alpha(1 \\to 0) &= \\min \\left(1, \\frac{p(0)}{p(1)}\\right) = \\min \\left(1, \\frac{\\frac{1}{3}}{\\frac{2}{3}}\\right) = \\frac{1}{2}, \\\\\n",
    "\\alpha(0 \\to 1) &= \\min \\left(1, \\frac{p(1)}{p(0)}\\right) = \\min \\left(1, \\frac{\\frac{2}{3}}{\\frac{1}{3}}\\right) = 1.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now, we compute the elements of the transition kernel \\( K \\):\n",
    "\n",
    "1. **Probability of Staying at 0**:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "K(0 \\to 0) &= q(1 \\mid 0) \\cdot (1 - \\alpha(0 \\to 1)) + q(0 \\mid 0) \\\\\n",
    "&= \\frac{1}{2} \\cdot (1 - 1) + \\frac{1}{2} \\\\\n",
    "&= 0.5.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "2. **Probability of Moving from 0 to 1**:\n",
    "$$\n",
    "K(0 \\to 1) = q(1 \\mid 0) \\cdot \\alpha(0 \\to 1) = \\frac{1}{2} \\cdot 1 = 0.5.\n",
    "$$\n",
    "\n",
    "3. **Probability of Moving from 1 to 0**:\n",
    "$$\n",
    "K(1 \\to 0) = q(0 \\mid 1) \\cdot \\alpha(1 \\to 0) = \\frac{1}{2} \\cdot \\frac{1}{2} = 0.25.\n",
    "$$\n",
    "\n",
    "4. **Probability of Staying at 1**:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "K(1 \\to 1) &= q(0 \\mid 1) \\cdot (1 - \\alpha(1 \\to 0)) + q(1 \\mid 1) \\\\\n",
    "&= \\frac{1}{2} \\cdot \\left(1 - \\frac{1}{2}\\right) + \\frac{1}{2} \\\\\n",
    "&= 0.75.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus, the transition kernel is:\n",
    "$$\n",
    "K = \\begin{bmatrix}\n",
    "0.5 & 0.5 \\\\\n",
    "0.25 & 0.75\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "The stationary distribution \\( \\pi = [\\pi_0, \\pi_1] \\) satisfies \\( \\pi K = \\pi \\). Solving:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\pi_0 &= 0.5 \\pi_0 + 0.25 \\pi_1, \\\\\n",
    "\\pi_1 &= 0.5 \\pi_0 + 0.75 \\pi_1, \\\\\n",
    "\\pi_0 + \\pi_1 &= 1.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Solving these equations yields:\n",
    "$$\n",
    "\\pi_0 = \\frac{1}{3}, \\quad \\pi_1 = \\frac{2}{3}.\n",
    "$$\n",
    "\n",
    "The stationary distribution \n",
    "$$\n",
    "(\\pi = \\left[\\frac{1}{3}, \\frac{2}{3}\\right]) \n",
    "$$\n",
    "matches the target distribution \\( p(x) \\), confirming that the Metropolis-Hastings algorithm converges to the correct stationary distribution.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
